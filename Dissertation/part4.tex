\chapter{Дифференциальная эволюция}\label{sec:radio}

\section{Обзор}
Эволюционные алгоритмы~(ЭА) — один из наиболее широко используемых методов решения сложных задач оптимизации. Несколько вариантов этих стратегий были разработаны и применены во многих областях, таких как наука, экономика и инженерия. Среди них дифференциальная эволюция~(ДЭ)~\cite{storn:de} — одна из наиболее эффективных стратегий непрерывной оптимизации. Более того, ДЭ была признана стратегией-победителем нескольких конкурсов по оптимизации~\cite{das:de}. Подобно другим EA, DE вдохновлен естественным процессом эволюции и включает в себя применение мутаций, рекомбинаций и селекции. Основная особенность метода de заключается в том, что он учитывает различия среди векторов, присутствующих в популяции, для изучения пространства поиска. В этом смысле он похож на оптимизаторы Nelder-Mead~\cite{nelder:simplex} и Controlled Random Search~(CRS)~\cite{price:global}.

ДЭ -- стохастический алгоритм на основе популяции, поэтому он итеративно выводит несколько наборов решений-кандидатов. В ДЭ такие решения-кандидаты обычно называются векторами. В базовом варианте ДЭ для каждого члена популяции~(их называют целевыми векторами) создается новый мутантный вектор. Затем мутантный вектор комбинируют с целевым вектором для создания пробного вектора. Наконец, применяется фаза селекции для выбора выживших. Таким образом, несколько поколений эволюционируют, пока не будет достигнут критерий остановки. В поколении $G$ i-й вектор популяции обозначается как $\textbf{X}_{i,G} = [x_{1,i,G}, x_{2,i,G}, ..., x_{D,i,G}]$. Ниже приведены более подробные сведения о каждой фазе ДЭ.

Эксперименты показывают, что в целом эволюция популяции соответствует динамике случайного облака точек, движущегося как целое вдоль рельефа оптимизируемой функции, повторяя его характерные особенности. В случае попадания в овраг <<облако>> принимает форму этого оврага и распределение точек становится таким, что математическое ожидание разности двух случайных векторов оказывается направленным вдоль длинной стороны оврага. Это обеспечивает быстрое движение вдоль узких вытянутых оврагов, тогда как для градиентных методов в аналогичных условиях характерно колебательная динамика «от стенки к стенке». Приведенные эвристические соображения иллюстрируют наиболее важную и привлекательную особенность алгоритма ДЭ -- способность динамически моделировать особенности рельефа оптимизируемой функции. Именно этим объясняется замечательная способность алгоритма быстро проходить сложные овраги, обеспечивая эффективность даже в случае сложного рельефа.

\subsection{Инициализация}

ДЭ обычно начинает процесс оптимизации со случайно инициированной популяции, состоящей из $D$ векторов. Поскольку информация о производительности различных регионов обычно отсутствует, обычно применяются однородные генераторы случайных чисел. Следовательно, $j$-я компонента $i$-го вектора инициализируется как $x_{j,i,0} = a_{j} + rand_{i,j}[0, 1](b_j − a_j )$, где $rand_{i,j} [0, 1]$ — равномерно распределенное случайное число, лежащее между 0 и 1.

\subsection{Мутация}

Для каждого целевого вектора создается мутантный вектор. В настоящее время известно несколько способов выполнения этого процесса. В классическом варианте ДЭ применяется стратегия $rand/1$. В этом случае мутантный вектор $\textbf{V}_{i,G}$ создается следующим образом:

\begin{equation}\label{eq:de_mut}
  \textbf{V}_{i,G} = \textbf{X}_{r1,G} + F \times (\textbf{X}_{r2,G} − \textbf{X}_{r3,G}) r1 \neq r2 \neq r3
\end{equation}

Индексы $r1, r2, r3 \in [1, D]$ — различные целые числа, случайно выбранные из диапазона [1, D]. Кроме того, все они отличаются от индекса~$i$. Важно учитывать, что разница между векторами масштабируется числом F, которое называется силой мутации и обычно определяется в интервале [0.4, 1].

\subsection{Рекомбинация}

Для объединения информации о различных решениях-кандидатах и с целью увеличения разнообразия применяется оператор кроссинговера. В частности, каждый целевой вектор~$\textbf{X}_{i,G}$ смешивается с соответствующим ему мутантным вектором~$\textbf{V}_{i,G}$ для создания пробного вектора $\textbf{U}_{i,G} = [u_{1,i,G}, u_{2,i,G}, ..., u_{D,i,G}]$. Наиболее типичным кроссовером является биномиальный, который работает следующим образом:
\begin{equation}\label{eq:de_crossover}
  \textbf{U}_{j,i,G} = 
    \begin{cases}
     v_{j,i,G}, & \mbox{если} rand_{i,j}[0, 1] \leq CR \mbox{или} j = j_{rand} \\
     x_{j,i,G}, & \mbox{иначе}
    \end{cases},
\end{equation}
где $rand_{i,j}[0, 1]$ -- равномерно распределенное случайное число, $j_{rand}$ -- случайно выбранный индекс, который гарантирует, что $\textbf{U}_{i,G}$ наследует хотя бы одну компоненту от $\textbf{V}_{i,G}$, $CR \in [0, 1]$ -- скорость кроссовера.

\subsection{Селекция}

Наконец, выполняется жадный отбор для определения оставшихся в живых следующего поколения. Каждый пробный вектор сравнивается с соответствующим ему целевым вектором, и выживает лучший из них:

\begin{equation}\label{eq:de_sel}
  \textbf{X}_{i,G+1} =
  \begin{cases}
    \textbf{U}_{i,G}, & \mbox{если} \tilde{F}(\textbf{U}_{i,G}) \leq \tilde{F}(\textbf{X}_{i,G}) \\
    \textbf{X}_{i,G}, & \mbox{иначе}.
  \end{cases}
\end{equation}

Следовательно, каждый член популяции либо становится лучше, либо остается с одной и той же объективной ценностью в каждом поколении.

\section{Эксперимент}

